{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "We will begin with the binary classification problem, which can then be trivially generalized to multi-class problems using OneVsOne or OneVsAll\n",
    "## 1. Notations\n",
    "$\\DeclareMathOperator{\\argmin} {arg min}\n",
    "\\DeclareMathOperator{\\argmax} {arg max}$\n",
    "- Let $E=\\mathbb{R}^m$ the vector space a features\n",
    "- Let $P=\\mathbb{R}^{m+1}$ be a vector space in which the parameters vary\n",
    "- For $\\omega \\in P$, we will denote $w_*=(w_1,..w_n)$\n",
    "- We will denote by $\\mathbb{1}_i \\in \\mathbb{R}^i $ the vector of ones $\\forall i \\in \\mathbb{N}$ \n",
    "- Let $F\\in \\mathscr{C}^1$ a cumulative probability function\n",
    "- Let $m\\in\\mathbb{N}^*$ the number of features.\n",
    "- Let $n \\in \\mathbb{N}^*$ the number of samples\n",
    "- Let $X \\in E^n$ be a tuple of input samples \n",
    "- Let $Y \\in \\{0,1\\}^n$ be a tuple of samples \n",
    "- Let $C \\in \\mathbb{R}_+$ be a hyperparameter\n",
    "- Let $\\mathscr{N}=\\lVert\\cdot\\rVert$ be a norm on $E$\n",
    "- Let $\\mathscr{l}\\in \\mathscr{F}\\left([0,1]^2,\\mathbb{R}\\right)$ the unit cost function\n",
    "- Let $\\mathscr{L} \\in \\mathscr{F}\\left(P,\\mathbb{R}\\right)/$\n",
    "$$\\forall \\omega \\in P,\\quad \\mathscr{L}(\\omega)=C\\sum_{i=1}^{n}\\mathscr{l}\\left(F(X_i^T\\omega_*+\\omega_0),Y_i\\right)+\\lVert \\omega_*\\rVert$$\n",
    "## 2. Objective\n",
    "We will try to find: $$\\omega_m=\\arg\\min_{\\omega\\in P} \\mathscr{L}(\\omega)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "126                6.2               2.8                4.8               1.8   \n",
       "33                 5.5               4.2                1.4               0.2   \n",
       "102                7.1               3.0                5.9               2.1   \n",
       "104                6.5               3.0                5.8               2.2   \n",
       "10                 5.4               3.7                1.5               0.2   \n",
       "\n",
       "     target      label  \n",
       "126       2  virginica  \n",
       "33        0     setosa  \n",
       "102       2  virginica  \n",
       "104       2  virginica  \n",
       "10        0     setosa  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "def createIRIS():\n",
    "    data=datasets.load_iris()\n",
    "    U=pd.DataFrame(data[\"data\"],columns=data[\"feature_names\"])\n",
    "    labels=pd.Series(data[\"target_names\"])\n",
    "    U[\"target\"]=data[\"target\"]\n",
    "    U[\"label\"]= [labels[i] for i in data[\"target\"]]\n",
    "    return U\n",
    "U = createIRIS()\n",
    "U.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=U[U.columns[:-2]]\n",
    "Y=U[U.columns[-2]]\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "from scipy.special import xlogy\n",
    "import scipy\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def dsig(x):\n",
    "    S=sigmoid(x)\n",
    "    return S*(1-S)\n",
    "\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self,C=1,p=0.5,F=sigmoid,dF=None,N=np.linalg.norm,N_args=[]):\n",
    "        self.C=C\n",
    "        self.p=p\n",
    "        self.F=F\n",
    "        self.dF=dF\n",
    "        self.cost=BinaryLogisticRegression.cost\n",
    "        self.N_args=N_args\n",
    "        self.N=lambda u:N(u,*self.N_args)\n",
    "        self.cost=BinaryLogisticRegression.cost\n",
    "    def predict(self,X):\n",
    "        return self.decision_function(X)>self.p\n",
    "    def decision_function(self,X):\n",
    "        return self.F(X@self.w[1:]+self.w[0])\n",
    "    def fit(self,X,Y):\n",
    "        self.w=optimize.minimize(lambda w:self.cost(X,Y,w,self.F,self.C,self.N),jac=None,x0=np.zeros(X.shape[1]+1)).x\n",
    "        return self\n",
    "    def parameters(self):\n",
    "        return self.w\n",
    "    def score(self,X,Y):\n",
    "        return (self.predict(X)==Y).mean()\n",
    "    @classmethod\n",
    "    def cost(cls,X,Y,w,F,C,N):\n",
    "        H=F(X@w[1:]+w[0])        \n",
    "        return -C*np.sum(xlogy(Y,H)+xlogy(1-Y,1-H))+N(w[1:])\n",
    "    pass\n",
    "\n",
    "class OneVsAllLogisticRegression:\n",
    "    def __init__(self,C=1,F=sigmoid,dF=None,N=np.linalg.norm,N_args=[],cost=BinaryLogisticRegression.cost):\n",
    "        self.C=C\n",
    "        self.F=F\n",
    "        self.dF=dF\n",
    "        self.N=N\n",
    "        self.cost=cost\n",
    "    def fit(self,X,Y):\n",
    "        X=np.array(X)\n",
    "        Y=np.array(Y)\n",
    "        self.k=np.max(Y)+1\n",
    "        self.W=np.zeros([X.shape[1]+1,self.k])\n",
    "        for i in range(self.k):\n",
    "            self.W[:,i]=BinaryLogisticRegression(C=self.C,F=self.F,dF=self.dF,N=self.N,N_args=self.N_args,cost=self.cost).fit(X,Y==i).parameters()\n",
    "        \n",
    "    def predict(self,X):\n",
    "        S=np.zeros([X.shape[0],self.k])\n",
    "        V=self.F(np.array(X)@self.W[1:,:]+self.W[0,:])\n",
    "        for s in range(X.shape[0]):\n",
    "            for i in range(self.k):\n",
    "                P=np.full(self.k,(1-V[s,i])/(self.k-1))\n",
    "                P[i]=V[s,i]\n",
    "                S[s,i]=S[s,i]+P[i]\n",
    "        return np.argmax(S,axis=1)\n",
    "    def parameters():\n",
    "        return self.W\n",
    "    pass\n",
    "        \n",
    "class OneVsOneLogisticRegression:\n",
    "    def __init__(self,C=1,F=sigmoid,dF=None,N=np.linalg.norm,N_args=[],cost=BinaryLogisticRegression.cost):\n",
    "        self.C=C\n",
    "        self.F=F\n",
    "        self.dF=dF\n",
    "        self.N=N\n",
    "        self.N_args=N_args\n",
    "        self.cost=cost\n",
    "    def fit(self,X,Y):\n",
    "        X=np.array(X)\n",
    "        Y=np.array(Y)\n",
    "        self.k=np.max(Y)+1\n",
    "        nCr=lambda a,b:int(scipy.special.comb(a,b))\n",
    "        m=nCr(self.k,2)\n",
    "        self.W=np.zeros([X.shape[1]+1,m])\n",
    "        for i in range(self.k):\n",
    "            for j in range(i):\n",
    "                mask=(Y==i)|(Y==j)\n",
    "                self.W[:,nCr(i,2)+j]=BinaryLogisticRegression(C=self.C,F=self.F,dF=self.dF,N=self.N,N_args=self.N_args,cost=self.cost).fit(X[mask],Y[mask]==j).parameters()\n",
    "        \n",
    "    def predict(self,X):\n",
    "        nCr=lambda a,b:int(scipy.special.comb(a,b))\n",
    "        m=nCr(self.k,2)\n",
    "        S=np.zeros([X.shape[0],self.k])\n",
    "        X=np.array(X)\n",
    "        V=self.F(X@self.W[1:,:]+self.W[0,:])\n",
    "        P=np.zeros(self.k)\n",
    "        for s in range(X.shape[0]):\n",
    "            for i in range(self.k):\n",
    "                for j in range(i):                    \n",
    "                    S[s,j]=S[s,j]+V[s,nCr(i,2)+j]\n",
    "                    S[s,i]=S[s,i]+1-V[s,nCr(i,2)+j]\n",
    "        return np.argmax(S,axis=1)\n",
    "    def parameters():\n",
    "        return self.W\n",
    "    pass\n",
    "\n",
    "class MultinomialLogisticRegression:\n",
    "    def __init__(self,C=1,F=sigmoid,dF=None,N=np.linalg.norm,N_args=[],cost=BinaryLogisticRegression.cost):\n",
    "        self.C=C\n",
    "        self.F=F\n",
    "        self.dF=dF\n",
    "        self.N=N\n",
    "        self.cost=cost\n",
    "    def fit(self,X,Y):\n",
    "        X=np.array(X)\n",
    "        Y=np.array(Y)\n",
    "        self.k=np.max(Y)+1\n",
    "        self.W=np.zeros([X.shape[1]+1,self.k])\n",
    "        for i in range(self.k):\n",
    "            self.W[:,i]=BinaryLogisticRegression(C=self.C,F=self.F,dF=self.dF,N=self.N).fit(X,Y==i).parameters()\n",
    "        \n",
    "    def predict(self,X):\n",
    "        S=np.zeros([X.shape[0],self.k])\n",
    "        V=self.F(np.array(X)@self.W[1:,:]+self.W[0,:])\n",
    "        \n",
    "        return np.argmax(V,axis=1)\n",
    "    def parameters():\n",
    "        return self.W\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S0(x):\n",
    "    if(x<=0):\n",
    "        return 0\n",
    "    return np.exp(-1/x**2)\n",
    "classifier=MultinomialLogisticRegression(C=10,N=lambda u:np.linalg.norm(u,ord=2),cost=lambda X,Y,w,F,C,N:\n",
    "                                      C*np.linalg.norm(F(X@w[1:]+w[0])-Y)+N(w[1:]))\n",
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print((classifier.predict(X_test)==Y_test).mean())\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(C=1000,max_iter=1000).fit(X_train,Y_train).score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC(kernel=\"poly\",degree=2).fit(X_train,Y_train).score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777458722182341\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 27 17:34:57 2020\n",
    "\n",
    "@author: Rami Zouari\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "spam=pd.read_csv(\"D:\\MachineLearning\\Formation\\Datasets\\spam.csv\",encoding=\"ISO-8859-1\")\n",
    "spam.fillna(\"\",inplace=True)\n",
    "spam[\"v2\"]=spam[spam.columns[1:]].apply(func=lambda u:\"\".join(u),axis=1)\n",
    "spam=spam[[\"v1\",\"v2\"]]\n",
    "vectorizer = text.CountVectorizer()\n",
    "Y=spam[\"v1\"]==\"spam\"\n",
    "X=spam[\"v2\"]\n",
    "vectorizer.fit(X)\n",
    "X1=vectorizer.transform(X)\n",
    "lsa=TruncatedSVD(n_components=100)\n",
    "lsa.fit(X1)\n",
    "X2=lsa.transform(X1)\n",
    "X_train,X_test,Y_train,Y_test= train_test_split(X2,Y)\n",
    "predictor=BinaryLogisticRegression()\n",
    "predictor.fit(X_train,Y_train)\n",
    "print(predictor.score(X_test,Y_test))\n",
    "sns.heatmap(confusion_matrix(Y_test,predictor.predict(X_test)),annot=True)\n",
    "model = Pipeline([(\"TextVectorizer\",vectorizer),(\"LSA\",lsa,),(\"predictor\",predictor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
