{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIRIS():\n",
    "    data=datasets.load_iris()\n",
    "    U=pd.DataFrame(data[\"data\"],columns=data[\"feature_names\"])\n",
    "    labels=pd.Series(data[\"target_names\"])\n",
    "    U[\"target\"]=data[\"target\"]\n",
    "    U[\"label\"]= [labels[i] for i in data[\"target\"]]\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target      label  \n",
       "0         0     setosa  \n",
       "1         0     setosa  \n",
       "2         0     setosa  \n",
       "3         0     setosa  \n",
       "4         0     setosa  \n",
       "..      ...        ...  \n",
       "145       2  virginica  \n",
       "146       2  virginica  \n",
       "147       2  virginica  \n",
       "148       2  virginica  \n",
       "149       2  virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=U[U.columns[:-2]]\n",
    "Y=U[U.columns[-2]]\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$-Nearest Neighbour\n",
    "$\\DeclareMathOperator{\\argmin} {arg min}\n",
    "\\DeclareMathOperator{\\argmax} {arg max}$\n",
    "- Let $m\\in\\mathbb{N}^*$ the number of features.\n",
    "- Let $n \\in \\mathbb{N}^*$ the number of samples\n",
    "- Let $X \\in \\mathbb{R}^{n\\times m}$\n",
    "- Let $d$ be a distance (or pseudo-distance) function on the metric space $\\mathbb{R}^m$\n",
    "- Let $k \\in \\mathbb{N}^*$ the number of neighbours to consider \n",
    "- $(\\omega _p)_{p\\in \\left\\{1,..,k \\right\\}} \\in [0,1]^{k}/\\sum_{p=1}^{k}\\omega_p = 1$\n",
    "- Let $S \\in \\mathscr{F}\\left(\\mathbb{R}^{n},\\mathbb{R}^{m}\\right)/\\forall x \\in \\mathbb{R}^n,\\forall i \\in \\left\\{1,..,n\\right\\}, S_i(x) = d(X_i,x)$\n",
    "- Let $x\\in \\mathbb{R}^m,$ we will order $(S_p(x))_{p\\in \\{1,..,n\\} }$ with respect to the total order $\\le$:\n",
    "$$ S_{m_1}(x) \\le S_{m_i}(x) \\le .. \\le S_{m_n}(x) $$\n",
    "\n",
    "## 1. Classification\n",
    "- Let $p\\in\\mathbb{N}^*$ the number of classes\n",
    "- Let $Y \\in \\{1,..,p\\}^{n}$\n",
    "- The predicted class of $x$ will be:\n",
    "$$ \\tilde{y}=\\arg \\max_{l\\in \\{1,..,p\\}}\\sum_{\\substack{i=1 \\\\ Y_{m_i}=l}}^{k}\\omega_{m_i}$$\n",
    "### For $k$=1, this can be simplified to:\n",
    "$$ \\begin{split} \\tilde{y}=Y_s \\\\ s=\\arg \\min_{i\\in \\{1,..,n\\}}S_i(x) \\end{split}$$\n",
    "\n",
    "## 2. Regression\n",
    "- Let $p\\in\\mathbb{N}^*$ the number of classes\n",
    "- Let $Y \\in F$ where $F$ is a vector space.\n",
    "\n",
    "We have:\n",
    "$$ \\tilde{y}=\\frac{\\sum_{i=1}^{k}\\omega_{m_i}Y_{m_i}}{\\sum_{i=1}^{k}\\omega_{m_i}}$$\n",
    "\n",
    "### For $k$=1, this can be simplified to:\n",
    "$$ \\begin{split} \\tilde{y}=Y_s \\\\ s=\\arg \\min_{i\\in \\{1,..,n\\}}S_i(x) \\end{split}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import heapq\n",
    "\n",
    "        \n",
    "\n",
    "class NearestNeighbourClassifier:\n",
    "    def fit(self,X,Y):\n",
    "        self.X=np.array(X)\n",
    "        self.Y=np.array(Y)\n",
    "    def predictOne(self,x):\n",
    "        S=self.X-x\n",
    "        p=np.argmin(np.sum(S**2,axis=1))\n",
    "        return self.Y[p]\n",
    "    def predict(self,X):\n",
    "        return np.apply_along_axis(self.predictOne,axis=-1,arr=X)\n",
    "    def score(self,X,Y):\n",
    "        return np.mean(self.predict(X)==Y)\n",
    "    pass\n",
    "\n",
    "\n",
    "class KNearestNeighbourClassifier:\n",
    "    def __init__(self,k=5,w=None,d= lambda X1,X2:np.sqrt(np.sum((X2-X1)**2,axis=1))):\n",
    "        self.k=k\n",
    "        self.w=w\n",
    "        self.d=d\n",
    "    def fit(self,X,Y):\n",
    "        self.X=np.array(X)\n",
    "        self.Y=np.array(Y)\n",
    "    def predictOne(self,x):\n",
    "        S=self.X-x\n",
    "        R=heapq.nsmallest(self.k,zip(self.d(self.X,x),range(0,self.X.shape[0])))\n",
    "        P=np.zeros(self.k)\n",
    "        w=None\n",
    "        for s in range(0,self.k):\n",
    "            P[s]=self.Y[R[s][1]]\n",
    "        if self.w== None:\n",
    "            w=[1]*self.k\n",
    "        elif callable(self.w):\n",
    "            w=[self.w(i) for i in range(0,self.k)]\n",
    "        else: w=self.w\n",
    "#        M=pd.Series(P)\n",
    "#        return M.value_counts().idxmax()\n",
    "        df=pd.DataFrame([P,w],index=[\"Y\",\"p\"]).T\n",
    "        V=df.groupby(\"Y\").sum()\n",
    "        return V[\"p\"].idxmax()\n",
    "    def predict(self,X):\n",
    "        return np.apply_along_axis(self.predictOne,axis=-1,arr=X)\n",
    "    def score(self,X,Y):\n",
    "        return np.mean(self.predict(X)==Y)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157894736842105"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def std_distance(X1,X2,std):\n",
    "    S=X2-X1\n",
    "    S=S/np.array(std)\n",
    "    return np.sqrt(np.sum(S**2,axis=1))\n",
    "    \n",
    "    \n",
    "\n",
    "model=KNearestNeighbourClassifier(100,d=lambda X1,X2:std_distance(X1,X2,np.std(X_train,axis=0)),w=lambda i:np.float_power(i+1,-1/8))\n",
    "model.fit(X_train,Y_train)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02031345, 0.01768389, 0.01630645, 0.01539472, 0.01472278,\n",
       "       0.01419559, 0.01376462, 0.01340188, 0.01308987, 0.01281692,\n",
       "       0.01257492, 0.01235798, 0.01216172, 0.01198279, 0.01181858,\n",
       "       0.01166701, 0.01152641, 0.01139539, 0.01127283, 0.01115778,\n",
       "       0.01104943, 0.0109471 , 0.01085021, 0.01075825, 0.01067077,\n",
       "       0.01058739, 0.01050778, 0.01043163, 0.01035867, 0.01028868,\n",
       "       0.01022142, 0.01015673, 0.01009441, 0.01003432, 0.00997631,\n",
       "       0.00992026, 0.00986605, 0.00981357, 0.00976272, 0.00971341,\n",
       "       0.00966556, 0.00961909, 0.00957393, 0.00953001, 0.00948727,\n",
       "       0.00944566, 0.00940512, 0.0093656 , 0.00932705, 0.00928944,\n",
       "       0.00925273, 0.00921686, 0.00918182, 0.00914755, 0.00911405,\n",
       "       0.00908126, 0.00904917, 0.00901775, 0.00898697, 0.00895681,\n",
       "       0.00892725, 0.00889827, 0.00886984, 0.00884194, 0.00881457,\n",
       "       0.00878769, 0.0087613 , 0.00873538, 0.00870991, 0.00868489,\n",
       "       0.00866028, 0.00863609, 0.0086123 , 0.0085889 , 0.00856587,\n",
       "       0.00854321, 0.0085209 , 0.00849894, 0.00847731, 0.00845601,\n",
       "       0.00843503, 0.00841436, 0.00839398, 0.0083739 , 0.00835411,\n",
       "       0.00833459, 0.00831534, 0.00829635, 0.00827762, 0.00825915,\n",
       "       0.00824092, 0.00822292, 0.00820516, 0.00818763, 0.00817032,\n",
       "       0.00815323, 0.00813635, 0.00811967, 0.0081032 , 0.00808693])"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.float_power(i+1,-1/5) for i in range(100)])/np.sum(np.array([np.float_power(i+1,-1/5) for i in range(100)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23684210526315788"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNeighborsClassifier(n_neighbors=100).fit(X_train,Y_train).score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Neighbours\n",
    "$\\DeclareMathOperator{\\argmin} {arg min}\n",
    "\\DeclareMathOperator{\\argmax} {arg max}$\n",
    "- Let $m\\in\\mathbb{N}^*$ the number of features.\n",
    "- Let $n \\in \\mathbb{N}^*$ the number of samples\n",
    "- Let $X \\in \\mathbb{R}^{n\\times m}$\n",
    "- Let $d$ be a distance (or pseudo-distance) function on the metric space $\\mathbb{R}^m$\n",
    "- Let $S \\in \\mathscr{F}\\left(\\mathbb{R}^{n},\\mathbb{R}^{m}\\right)/\\forall x \\in \\mathbb{R}^n,\\forall i \\in \\left\\{1,..,n\\right\\}, S_i(x) = d(X_i,x)$\n",
    "- Let $x\\in \\mathbb{R}^m$\n",
    "- Let $f$ be a decreasing function\n",
    "## 1. Classification\n",
    "- Let $p\\in\\mathbb{N}^*$ the number of classes\n",
    "- Let $Y \\in \\{1,..,p\\}^{n}$\n",
    "- The predicted class of $x$ will be:\n",
    "$$ \\tilde{y}=\\arg \\max_{l\\in \\{1,..,p\\}}\\sum_{\\substack{i=1 \\\\ Y_{i}=l}}^{n}f\\left(S_i(x)\\right)$$\n",
    "\n",
    "## 2. Regression\n",
    "- Let $p\\in\\mathbb{N}^*$ the number of classes\n",
    "- Let $Y \\in F$ where $F$ is a vector space.\n",
    "\n",
    "We have:\n",
    "$$ \\tilde{y}=\\frac{\\sum_{i=1}^{n}f\\left(S_i(x)\\right)Y_{i}}{\\sum_{i=1}^{n}f\\left(S_i(x)\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "class AllNeighboursClassifier:\n",
    "    def __init__(self,f,df,d= lambda X1,X2:np.sqrt(np.sum((X2-X1)**2,axis=1)),**kwargs):\n",
    "        self.f=f\n",
    "        self.d=d\n",
    "        self.kwargs=kwargs\n",
    "    def fit(self,X,Y):\n",
    "        self.X=np.array(X)\n",
    "        self.Y=np.array(Y)\n",
    "        least_squares(fun, x0, jac=jac, bounds=(0, 100), args=(u, y), verbose=1)\n",
    "    def predictOne(self,x):\n",
    "        S=self.d(self.X,x)    \n",
    "        data=pd.DataFrame([Y,self.f(S,**self.kwargs)],index=[\"Y\",\"p\"]).T\n",
    "        V=data.groupby(\"Y\").sum()\n",
    "        return V[\"p\"].idxmax()\n",
    "    def predict(self,X):\n",
    "        return np.apply_along_axis(self.predictOne,axis=-1,arr=X)\n",
    "    def score(self,X,Y):\n",
    "        return np.mean(self.predict(X)==Y)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4107142857142857"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def g(x,mu:sig):\n",
    "    return np.exp(-(x-mu)**2/(2*sig**2))/(sig*np.sqrt(2*np.pi))\n",
    "\n",
    "def dg(x,mu,sig):\n",
    "    return [(x-mu),(x-mu)/sig**2-1]*g(x,mu,sig)/sig**2\n",
    "\n",
    "AllNClassifier = AllNeighboursClassifier(f=g,mu=0,sig=.)\n",
    "AllNClassifier.fit(X_train,Y_train)\n",
    "AllNClassifier.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
