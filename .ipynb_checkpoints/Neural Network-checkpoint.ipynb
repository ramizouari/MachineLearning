{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "30                 4.8               3.1                1.6               0.2   \n",
       "54                 6.5               2.8                4.6               1.5   \n",
       "107                7.3               2.9                6.3               1.8   \n",
       "66                 5.6               3.0                4.5               1.5   \n",
       "126                6.2               2.8                4.8               1.8   \n",
       "\n",
       "     target       label  \n",
       "30        0      setosa  \n",
       "54        1  versicolor  \n",
       "107       2   virginica  \n",
       "66        1  versicolor  \n",
       "126       2   virginica  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "def createIRIS():\n",
    "    data=datasets.load_iris()\n",
    "    U=pd.DataFrame(data[\"data\"],columns=data[\"feature_names\"])\n",
    "    labels=pd.Series(data[\"target_names\"])\n",
    "    U[\"target\"]=data[\"target\"]\n",
    "    U[\"label\"]= [labels[i] for i in data[\"target\"]]\n",
    "    return U\n",
    "U = createIRIS()\n",
    "U.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data3 = pd.read_csv(\"../Learning Test/heart_failure.csv\")\n",
    "data3.sample(10)\n",
    "X=StandardScaler().fit_transform(data3[data3.columns[:-1]])\n",
    "Y=data3[data3.columns[-1]]\n",
    "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# I Deriving Neural Network\n",
    "$\\DeclareMathOperator {\\Diag}{Diag}$\n",
    "## 1.Notations\n",
    "- We will denote by $\\mathbb{1}_i \\in \\mathbb{R}^i $ the vector of ones $\\forall i \\in \\mathbb{N}$ \n",
    "- $\\mathscr{A}\\left(E,F\\right)$ is the set of affine transformations between $E$ and $F$\n",
    "- Let $m=d_1$ the number of features.\n",
    "- Let $n \\in \\mathbb{N}^*$ the number of samples\n",
    "- Let $X \\in E^n$ be a tuple of input samples \n",
    "- Let $k=d_L$ the number of classes of the output\n",
    "- Let $y \\in \\{0,k-1\\}^n$ be a tuple of samples \n",
    "- Let $Y_i=(\\delta_{s,y_i})_{s\\in\\{1,\\dots,k\\}}\\forall i \\in \\{1,\\dots,n\\}$ the representation of each ouput on the neural network\n",
    "- Let $L\\in \\mathbb{N}_{\\ge 2}$ be the number of all layers\n",
    "- Let $d_1,\\dots,d_{L}$ be the dimension of the respective layer\n",
    "- Let $E_i=\\mathbb{R}^{d_i}$\n",
    "- Let $\\mathscr{A}_i=\\mathscr{A}\\left(E_{i-1},E_i\\right),i\\in\\left\\{2,\\dots,L\\right\\}$\n",
    "- Let $\\phi_i \\in \\mathscr{C}^1\\left(E_i,E_i\\right) \\forall i \\in \\{2,\\dots,L\\}$ be a series of activation functions with $\\phi_L$ a cumulative distribution function\n",
    "- Let $\\mathscr{K}=\\prod_{i=2}^L\\mathscr{A}_i$ the vector space in which the parameters vary\n",
    "- Let $\\Psi\\in \\mathscr{C}^1\\left(\\mathscr{K}\\times E_1,E_L\\right)/$\n",
    "$$\\forall \\boldsymbol{T}=(T_2,\\dots,T_L),\\in\\mathscr{K},\\forall u \\in E_1,\\quad\\Psi(\\boldsymbol{T},u)=\\left(\\bigcirc_{i=0}^{L-2}\\phi_{L-i}\\circ T_{L-i}\\right)(u)$$\n",
    "- Let $C \\in \\mathbb{R}_+$ be a hyperparameter\n",
    "- Let $\\mathscr{N}=\\lVert\\cdot\\rVert$ be a norm on $\\mathscr{K}$\n",
    "- Let $\\mathscr{l}\\in \\mathscr{F}\\left([0,1]^{k}\\times [0,1]^{k},\\mathbb{R}\\right)$ the unit cost function\n",
    "- Let $\\mathscr{L} \\in \\mathscr{F}\\left(\\mathscr{K},\\mathbb{R}\\right)/$\n",
    "$$\\forall \\boldsymbol{T} \\in \\mathscr{K},\\quad \\mathscr{L}(\\boldsymbol{T})=C\\sum_{i=1}^{n}\\mathscr{l}\\left(\\Psi(\\boldsymbol{T},X_i),Y_i\\right)+\\lVert \\boldsymbol{T}\\rVert$$\n",
    "- For each vector $X_i,i \\in \\{1,\\dots,n\\}$, We will denote by $\\left(^{(i)}a^{(j)}\\right)_{j\\in\\{1,\\dots,L\\}}$ and $\\left(^{(i)}z^{(j)}\\right)_{j\\in\\{1,\\dots,L\\}}$ the following sequences:\n",
    "$$\\begin{cases}^{(i)}a^{(1)}= ^{(i)}z^{(1)}=X_i \\\\ \n",
    "^{(i)}a^{(j)} = \\phi_i\\left(^{(i)}z^{(j)}\\right) \\\\\n",
    "^{(i)}z^{(j)} = T_i\\left(^{(i)}a^{(j-1)}\\right)\n",
    "\\end{cases}$$\n",
    "- We will use as a notation $\\dfrac{\\partial f}{\\partial u}\\left(u_0\\right)=J_f\\left(u_0\\right)$\n",
    "- We will denote a neural network any tuple $\\mathcal{N}=\\left(\\boldsymbol{E},\\boldsymbol{T},\\boldsymbol{\\phi}\\right)$, where: $$\\begin{cases} \n",
    "\\boldsymbol{E}=\\left(E_1,\\dots,E_L\\right) \\\\\n",
    "\\boldsymbol{\\phi}=\\left(\\phi_2,\\dots,\\phi_L\\right)\n",
    "\\end{cases}\n",
    "$$\n",
    "## 2. Objective\n",
    "We will try to find: $$\\boldsymbol{T}_*=\\arg\\min_{\\boldsymbol{T}\\in \\mathscr{K}} \\mathscr{L}(\\boldsymbol{T})$$\n",
    "## 3. Strategy\n",
    "The problem maybe too hard to crack globally, So assuming that $\\Phi$ is a $\\mathscr{C}^1$ function, we will fix a $\\boldsymbol{T}_0\\in \\mathscr{K}$ and try to find a local minimum close to $\\boldsymbol{T}_0$\n",
    "## 4. Backtracking\n",
    "Let $i\\in\\{1,\\cdots,n\\},j\\in \\{2,\\cdots,L\\}$\n",
    "We have the following identities:\n",
    "1. $$ \\dfrac{\\partial a^{(j)}}{\\partial z^{(j)}} =  \\dfrac{\\partial \\phi_j(z^{(j)})}{\\partial z^{(j)}} = \\dfrac{\\partial \\phi_j}{\\partial z^{(j)}}$$\n",
    "2. $$ \\dfrac{\\partial z^{(j)}}{\\partial a^{(j-1)}}= \\dfrac{\\partial \\left(T_j(a^{(j-1)})\\right)}{\\partial a^{(j-1)}}=\\dfrac{\\partial \\left(f_j(a^{(j-1)})+b_j\\right)}{\\partial a^{(j-1)}}=\\dfrac{\\partial f_j}{\\partial a^{(j-1)}}=f_j \\quad \\text{where }\n",
    "\\begin{cases} f_j=T_j-b_j \\in \\mathscr{L}\\left(E_{j-1},E_j\\right) \\\\ b_j=T_j(0)\n",
    "\\end{cases}$$ \n",
    "3. $$ \\dfrac{\\partial z^{(j)}}{\\partial f_j}= \\dfrac{\\partial \\left(f_j(z^{(j-1)})+b_j\\right)}{\\partial f_j}=\\dfrac{\\partial \\left(f_j(a^{(j-1)})\\right)}{\\partial f_j} = \\begin{pmatrix}\n",
    "(a^{(j-1)})^T & \\cdots & \\cdots & \\boldsymbol{0}_{E_{j-1}}^T\\\\\n",
    "\\boldsymbol{0}_{E_{j-1}}^T &  (a^{(j-1)})^T & \\cdots & \\boldsymbol{0}_{E_{j-1}}^T\\\\\n",
    "\\vdots & \\vdots & \\ddots  & \\boldsymbol{0}_{E_{j-1}}^T\\\\\n",
    "\\boldsymbol{0}_{E_{j-1}}^T & \\cdots & \\cdots & (a^{(j-1)})^T\n",
    "\\end{pmatrix} $$\n",
    "4. $$ \\dfrac{\\partial z^{(j)}}{\\partial b_j}= \\dfrac{\\partial \\left(f_j(a^{(j-1)})+b_j\\right)}{\\partial b_j}= I_{d_j} $$\n",
    "5. $$\\dfrac{\\partial z^{(j)}}{\\partial T_j} = \n",
    "\\begin{pmatrix}\n",
    "\\dfrac{\\partial z^{(j)}}{\\partial f_j} & \\dfrac{\\partial z^{(j)}}{\\partial b_j}\n",
    "\\end{pmatrix}=\n",
    " \\begin{pmatrix}\n",
    "(a^{(j-1)})^T & \\cdots & \\cdots & \\boldsymbol{0}_{E_{j-1}}^T & 1 & 0 & \\cdots & 0\\\\\n",
    "\\boldsymbol{0}_{E_{j-1}}^T &  (a^{(j-1)})^T & \\cdots & \\boldsymbol{0}_{E_{j-1}}^T & 0 &1 & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots  & \\boldsymbol{0}_{E_{j-1}}^T & \\vdots & \\vdots & \\ddots & \\vdots & \\\\\n",
    "\\boldsymbol{0}_{E_{j-1}}^T & \\cdots & \\cdots & (a^{(j-1)})^T & 0 & \\cdots & \\cdots & 1\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "### Jacobian of Special Activation functions:\n",
    "Here raising a vector to an exponent is done element wise.\n",
    "1. Hyperbolic tangent $\\phi_j=\\tanh$ applied element-wise:\n",
    "$$ \\dfrac{\\partial a^{(j)}}{\\partial z^{(j)}} = \\dfrac{\\partial \\phi_j}{\\partial z^{(j)}}= \\Diag\\left(\\phi_j'(z^{(j)})\\right)=\\Diag\\left(\\mathbb{1}-\\left(\\phi(z^{(j)})\\odot\\phi(z^{(j)})\\right)\\right)=\\Diag\\left(\\mathbb{1}-\\left(\\phi(z^{(j)})^2\\right)\\right)=\\Diag\\left(\\mathbb{1}-\\left((a^{(j)})^2\\right)\\right)$$\n",
    "2. Logistic function $\\phi_j=\\sigma$ applied element-wise: \n",
    "$$ \\dfrac{\\partial a^{(j)}}{\\partial z^{(j)}} = \\dfrac{\\partial \\phi_j}{\\partial z^{(j)}}= \\Diag\\left(\\phi_j'(z^{(j)})\\right)=\\Diag\\left(\\sigma(z^{(j)})\\odot\\left(\\mathbb{1}-\\sigma(z^{(j)})\\right) \\right)=\\Diag\\left(a^{(j)}\\odot\\left(\\mathbb{1}-a^{(j)}\\right) \\right)$$£\n",
    "\n",
    "3. Guassian function $\\phi_j=g=e^{-x^2}$:\n",
    "$$ \\dfrac{\\partial a^{(j)}}{\\partial z^{(j)}} = \\dfrac{\\partial \\phi_j}{\\partial z^{(j)}}= \\Diag\\left(g'(z^{(j)})\\right)=-2\\Diag\\left(z^{(j)}\\odot g\\left(z^{(j)}\\right)\\right)=-2\\Diag\\left(z^{(j)} \\odot a^{(j)} \\right)$$\n",
    "\n",
    "# II. Implementing Neural Network\n",
    "For simplicity, the implemenatation will use only one activation function: $\\sigma$\n",
    "## 1. Creating Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.special import xlogy\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class NeuralNetworkDesigner:\n",
    "    def __init__(self,x_dim,y_dim):\n",
    "        x_dim=int(x_dim)\n",
    "        y_dim=int(y_dim)\n",
    "        self.design=[x_dim]\n",
    "        self.y_dim=y_dim\n",
    "    def add_layer(self,dim):\n",
    "        self.design.append(dim)\n",
    "        return self\n",
    "    def get_design(self):\n",
    "        return self.design+[self.y_dim]\n",
    "    def reshape(self,U):\n",
    "        design=self.get_design()\n",
    "        M=[]\n",
    "        k=0\n",
    "        b=[]\n",
    "        for i in range(len(design)-1):\n",
    "            M.append(np.reshape(U[k:k+design[i]*design[i+1]],[design[i+1],design[i]]))\n",
    "            k=k+design[i]*design[i+1]\n",
    "            b.append(U[k:k+design[i+1]])\n",
    "            k=k+design[i+1]            \n",
    "        return M,b\n",
    "    def flatten(self,M,b):\n",
    "        design=self.get_design()\n",
    "        S=np.array(design)\n",
    "        s=np.sum(S[:-1]*S[1:])\n",
    "        r=np.sum(S[1:])\n",
    "        U=np.zeros(s+r)\n",
    "        k=0\n",
    "        for i in range(len(design)-1):\n",
    "            U[k:k+design[i]*design[i+1]]=np.ndarray.flatten(M[i])\n",
    "            k=k+design[i]*design[i+1]\n",
    "            U[k:k+design[i+1]]=b[i]\n",
    "            k=k+design[i+1]\n",
    "        return U\n",
    "    def flattened_dimension(self):\n",
    "        S=np.array(self.get_design())\n",
    "        return np.sum(S[:-1]*S[1:])+np.sum(S[1:])\n",
    "    def xdim(self):\n",
    "        return self.design[0]\n",
    "    def ydim(self):\n",
    "        return self.y_dim\n",
    "    pass\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, designer,C=1):\n",
    "        self.M=[]\n",
    "        self.designer=designer\n",
    "        self.design=self.designer.get_design()\n",
    "        self.b=[]\n",
    "        self.C=C\n",
    "        self.L=len(self.design)\n",
    "        for i in range(self.L-1):\n",
    "            self.M.append(np.random.normal(0,1,[self.design[i+1],self.design[i]]))\n",
    "            self.b.append(np.random.normal(0,1,[self.design[i+1]]))\n",
    "    \n",
    "    def _predictOne(self,x):\n",
    "        a = self.decision_function_1(x)\n",
    "        return np.argmax(a,axis=0)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.apply_along_axis(self._predictOne,arr=X.T,axis=0)\n",
    "    \n",
    "    def _unit_cost(self,u,w=None,retJac=False):\n",
    "        y=u[-1]\n",
    "        x=u[:-1]\n",
    "        M,b=self.designer.reshape(w)\n",
    "        a=[x]\n",
    "        z=[x]\n",
    "        for i in range(0,self.L-1):\n",
    "            z.append(M[i]@a[i]+b[i])\n",
    "            a.append(sigmoid(z[-1]))\n",
    "        k=self.designer.ydim()\n",
    "        v=np.zeros(k)\n",
    "        v[int(y)]=1\n",
    "        v_predicted=a[-1]\n",
    "        l=-xlogy(v,v_predicted)-xlogy(1-v,1-v_predicted)\n",
    "        if not retJac:\n",
    "            return np.sum(l)\n",
    "        chain = (a[-1]-v)\n",
    "        k=self.designer.flattened_dimension()\n",
    "        jac=np.zeros([1,k])\n",
    "        design=self.designer.get_design()\n",
    "        for i in range(self.L-1,0,-1):\n",
    "            if i<self.L-1:\n",
    "                chain=chain@np.diag(a[i]*(1-a[i]))\n",
    "            k=k-design[i]\n",
    "            jac[0,k:k+design[i]]=chain\n",
    "            k=k-design[i]*design[i-1]        \n",
    "            J=np.zeros([design[i],design[i]*design[i-1]])\n",
    "            for j in range(0,design[i]):\n",
    "                J[j,j*design[i-1] : (j+1)*design[i-1]]=a[i-1].T\n",
    "            jac[0,k:k+design[i-1]*design[i]]=chain@J\n",
    "            chain=chain@M[i-1]\n",
    "        return np.sum(l),jac\n",
    "    \n",
    "    def cost(self,X,Y,w=None,retJac=False):\n",
    "        if w is None:\n",
    "            w=nn.flattened_parameters()\n",
    "        S=self.designer.ydim()*X.shape[0]\n",
    "        R=np.apply_along_axis(lambda u,w:self._unit_cost(u,w,retJac=retJac),arr=np.c_[X,Y],axis=1,w=w)\n",
    "        L2=np.linalg.norm(w)\n",
    "        if not retJac:\n",
    "            return (self.C*np.sum(R)+0*L2)/S\n",
    "        L=self.C*np.sum(R[:,0])+0*L2\n",
    "        jac=np.ndarray.flatten(self.C*np.sum(R[:,1],axis=-1)+0*w.T/L2)\n",
    "        return L/S,jac/S\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        self.M,self.b=self.designer.reshape(minimize(lambda w:self.cost(X,Y,w,retJac=True),\n",
    "                                      x0= self.designer.flatten(self.M,self.b),jac=True).x)\n",
    "        return self\n",
    "    \n",
    "    def decision_function_1(self,x):\n",
    "        y=x\n",
    "        for i in range(0,self.L-1):\n",
    "            y=sigmoid(self.M[i]@y+self.b[i])\n",
    "        return y\n",
    "    \n",
    "    def decision_function(self,X):\n",
    "        return np.apply_along_axis(self.decision_function_1,arr=X,axis=1)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.M,self.b\n",
    "    \n",
    "    def flattened_parameters(self):\n",
    "        return self.designer.flatten(self.M,self.b)\n",
    "    \n",
    "    def score(self,X,Y):\n",
    "        return (self.predict(X)==Y).mean()\n",
    "    pass\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "designer = NeuralNetworkDesigner(X.shape[1],2)\n",
    "designer.add_layer(6).add_layer(4)\n",
    "nn=NeuralNetwork(designer,C=1)\n",
    "T=nn.flattened_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verifying Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between given gradient and the approximated gradient using finite difference:\n",
      "6.631048859867203e-08\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import check_grad\n",
    "checker= check_grad(lambda T: nn.cost(X,Y,T),x0=designer.flatten(nn.M,nn.b),grad=lambda T: nn.cost(X,Y,T,retJac=True)[1])\n",
    "print(\"Euclidean distance between given gradient and the approximated gradient using finite difference:\\n{}\".format(checker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Before training: 0.9130775969754096\n",
      "Gradient Norm Before training: 0.4524978835355027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rami Zouari\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n",
      "C:\\Users\\Rami Zouari\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost After training: 0.0864958127577532\n",
      "Gradient Norm After training: 2.319668283494395e-05\n"
     ]
    }
   ],
   "source": [
    "oldCost,oldJac=nn.cost(X_train,Y_train,retJac=True)\n",
    "print(\"Cost Before training: {}\".format(oldCost))\n",
    "print(\"Gradient Norm Before training: {}\".format(np.linalg.norm(oldJac)))\n",
    "nn.fit(X_train,Y_train)\n",
    "T=nn.flattened_parameters()\n",
    "newCost,newJac=nn.cost(X_train,Y_train,retJac=True)\n",
    "print(\"Cost After training: {}\".format(newCost))\n",
    "print(\"Gradient Norm After training: {}\".format(np.linalg.norm(newJac)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Accuarcy\n",
      "Training Accuarcy 0.9748953974895398\n",
      "Testing Accuarcy 0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking Accuarcy\")\n",
    "print(\"Training Accuarcy {}\".format(nn.score(X_train,Y_train)))\n",
    "print(\"Testing Accuarcy {}\".format(nn.score(X_test,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix of the model')"
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(Y_test,nn.predict(X_test)),annot=True)\n",
    "plt.title(\"Confusion Matrix of the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.94056415e-01, -1.44518820e+00,  2.55443576e+00,  3.47650838e+00,\n",
       "        8.58164902e+01,  3.49294461e+01,  6.00548277e+01,  1.32661529e+01,\n",
       "        9.50066666e+02,  5.09782606e+02,  5.07653535e+02,  9.54142594e+01,\n",
       "        4.90584139e-01,  1.62798393e+01,  1.80227950e+02, -2.43860836e+05,\n",
       "        3.43111166e+04,  3.42030064e+04,  8.20702559e+00,  2.34240120e+01,\n",
       "       -6.15327614e+01,  1.96320502e+05, -6.54937215e+04, -6.53098664e+04,\n",
       "        3.43195478e+04,  2.98527701e+01, -6.55108824e+04])"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tikzset{%\n",
    "  every neuron/.style={\n",
    "    circle,\n",
    "    draw,\n",
    "    minimum size=1cm\n",
    "  },\n",
    "  neuron missing/.style={\n",
    "    draw=none, \n",
    "    scale=4,\n",
    "    text height=0.333cm,\n",
    "    execute at begin node=\\color{black}$\\vdots$\n",
    "  },\n",
    "}\n",
    "\n",
    "\\begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]\n",
    "\n",
    "\\foreach \\m/\\l [count=\\y] in {1,2,3,missing,4}\n",
    "  \\node [every neuron/.try, neuron \\m/.try] (input-\\m) at (0,2.5-\\y) {};\n",
    "\n",
    "\\foreach \\m [count=\\y] in {1,missing,2}\n",
    "  \\node [every neuron/.try, neuron \\m/.try ] (hidden-\\m) at (2,2-\\y*1.25) {};\n",
    "\n",
    "\\foreach \\m [count=\\y] in {1,missing,2}\n",
    "  \\node [every neuron/.try, neuron \\m/.try ] (output-\\m) at (4,1.5-\\y) {};\n",
    "\n",
    "\\foreach \\l [count=\\i] in {1,2,3,n}\n",
    "  \\draw [<-] (input-\\i) -- ++(-1,0)\n",
    "    node [above, midway] {$I_\\l$};\n",
    "\n",
    "\\foreach \\l [count=\\i] in {1,n}\n",
    "  \\node [above] at (hidden-\\i.north) {$H_\\l$};\n",
    "\n",
    "\\foreach \\l [count=\\i] in {1,n}\n",
    "  \\draw [->] (output-\\i) -- ++(1,0)\n",
    "    node [above, midway] {$O_\\l$};\n",
    "\n",
    "\\foreach \\i in {1,...,4}\n",
    "  \\foreach \\j in {1,...,2}\n",
    "    \\draw [->] (input-\\i) -- (hidden-\\j);\n",
    "\n",
    "\\foreach \\i in {1,...,2}\n",
    "  \\foreach \\j in {1,...,2}\n",
    "    \\draw [->] (hidden-\\i) -- (output-\\j);\n",
    "\n",
    "\\foreach \\l [count=\\x from 0] in {Input, Hidden, Ouput}\n",
    "  \\node [align=center, above] at (\\x*2,2) {\\l \\\\ layer};\n",
    "\n",
    "\\end{tikzpicture}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
