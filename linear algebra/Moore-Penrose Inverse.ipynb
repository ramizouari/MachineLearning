{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Notations & Definitions\n",
    "$$\\DeclareMathOperator{\\id}{id}\n",
    "\\DeclareMathOperator{\\im}{Im}\n",
    "\\DeclareMathOperator{\\mat}{mat}\n",
    "$$\n",
    "### 1. Notations\n",
    "- Let $\\mathbb{K}\\in \\left\\{\\mathbb{R},\\mathbb{C}\\right\\}$\n",
    "- Let $E$ and $F$ be two finite dimensional inner product spaces over $\\mathbb{K}$ with respective dimensions $n,m\\in\\mathbb{N}$\n",
    "- We will denote by $\\mu_f\\in\\mathbb{K}\\left[x\\right]$ the minimal polynomial over $\\mathbb{K}$ of $f$\n",
    "- We will denote by $\\chi_f\\in\\mathbb{K}\\left[x\\right]$ the minimal polynomial over $\\mathbb{K}$ of $f$\n",
    "- We will denote for $f\\in\\mathscr{L}\\left(H\\right)$ by $H_{f,\\lambda}=\\ker\\left(f-\\lambda\\id\\right)$\n",
    "- We will denote for $f\\in\\mathscr{L}\\left(H\\right)$ by $H_{f,\\lambda,\\alpha}=\\ker\\left(f-\\lambda\\id\\right)^\\alpha$\n",
    "- We will denote by $\\Pi_H$ the orthogonal projection on $H$\n",
    "\n",
    "### 2. Definition of Moore-Penrose pseudoinverse\n",
    "We call a Moore-Penrose inverse of a linear function  $f\\in\\mathscr{L}\\left(E,F\\right)$ every linear function  $\\phi\\in\\mathscr{L}\\left(F,E\\right)$ satisfying:\n",
    "1. $\\phi\\circ f\\circ \\phi=\\phi$\n",
    "2. $f\\circ \\phi\\circ f=f$\n",
    "3. $\\phi\\circ f,f\\circ \\phi$ are both self-adjoint operators\n",
    "\n",
    "## 2. Relation between $\\mu_{f\\circ g}$ & $\\mu_{g\\circ f}$\n",
    "$$ \\mu_{f\\circ g}=\\sum_{i}a_ix^i \\\\\n",
    "\\implies \\mu_{f\\circ g}\\left(f\\circ g\\right)=\\sum_{i}a_i\\left(f\\circ g\\right)^i\\implies g\\circ\\mu_{f\\circ g}\\left(f\\circ g\\right)\\circ f= \\sum_{i}a_i g\\circ\\left(f\\circ g\\right)^i\\circ f = \\sum_{i}a_i \\left(g\\circ f\\right)^{i+1}=0\\\\\n",
    "\\implies \\mu_{g\\circ f} \\mid x\\mu_{f\\circ g}\n",
    "$$\n",
    "Also by symmetry, we have $\\mu_{f\\circ g} \\mid x\\mu_{g\\circ f}$\n",
    "We have then $$\\begin{cases}1\\le\\deg \\mu_{f\\circ g} \\le 1+\\deg \\mu_{g\\circ f}\\\\\n",
    "1 \\le \\deg \\mu_{g\\circ f} \\le 1+\\deg \\mu_{f\\circ g} \n",
    "\\end{cases} \\implies \\deg \\mu_{f\\circ g}-\\deg \\mu_{g\\circ f} \\in \\{-1,0,1\\}\n",
    "$$\n",
    "### 2.1 $\\deg \\mu_{f\\circ g}=1+\\deg \\mu_{g\\circ f}$\n",
    "We have $\\begin{cases}\\deg \\mu_{f\\circ g} = \\deg x\\mu_{g\\circ f}\\\\\n",
    " \\mu_{f\\circ g}  \\mid x \\mu_{g\\circ f} \n",
    "\\end{cases}$ and both polynomials are monic, we have then $ \\mu_{f\\circ g}=x\\mu_{g\\circ f}$\n",
    "### 2.2 $\\deg \\mu_{g\\circ f}=1+\\deg \\mu_{f\\circ g}$\n",
    "we have: $ \\mu_{g\\circ f}=x\\mu_{f\\circ g}$\n",
    "### 2.3 $\\deg \\mu_{f\\circ g}=\\deg \\mu_{g\\circ f}$\n",
    "We have then \n",
    "\n",
    "## 3. Eigenspaces of $f\\circ g$ & $g\\circ f$\n",
    "We will work for $\\mathbb{K}=\\mathbb{C}$\n",
    "$f\\in\\mathscr{L}\\left(E,F\\right),g\\in\\mathscr{L}\\left(F,E\\right)$\n",
    "Let $(\\lambda_i)_i$ be the distinct eigenvalues of $g\\circ f$ and $(\\alpha_i)_i$ their respective geometric multiplicties.\n",
    "\n",
    "We have: $$ \\bigoplus_i E_{g\\circ f,\\lambda_i,\\alpha_i}=\\bigoplus_i \\ker\\left(g\\circ f- \\lambda_i \\id \\right)^{\\alpha_i}$$\n",
    "- Let $\\lambda\\in\\mathbb{C}^*$ a non zero eigenvalue of $g\\circ f$ with geometric multiplicity $\\alpha$\n",
    "- Let $\\mathscr{B} = \\left(u_1,\\dots,u_p\\right)$ a basis of $E_{g\\circ f,\\lambda,\\alpha}$\n",
    "\n",
    "\n",
    "\n",
    "## 4. Eigendecomposition of $f^*\\circ f$ and  $f\\circ f^*$ \n",
    "Without Loss of generality, we assume that $n \\le m$\n",
    "Because $f\\circ f^*$ and $f^*\\circ f$ are both self-adjoint operators, they are both diagonilisable\n",
    "Let $\\mathscr{B_1}=\\left(u_1,\\dots,u_m\\right)$ an orthonormal basis of eigenvectors of $f^*\\circ f$ with their respective eigenvalues $\\left(\\lambda_1,\\dots,\\lambda_m\\right)$\n",
    "\n",
    "Let $\\mathscr{B_1}=\\left(u_1,\\dots,u_m\\right)$ an orthonormal basis of eigenvectors of $f^*\\circ f$ with their respective eigenvalues $\\left(\\lambda_1,\\dots,\\lambda_m\\right)$\n",
    "\n",
    "## 5. Existence & Uniqueness\n",
    "\n",
    "### 5.1 Uniqueness by construction\n",
    "Let $f\\in \\mathscr{L}\\left(E,F\\right)$ and $g$ a Moore-Penrose inverse of $f$\n",
    "We have $g\\circ f$ is self-adjoint, so it has an orthonormal basis of eigenvectors\n",
    "\n",
    "let $\\left(\\lambda,u\\right)$ an eigen value-vector couple of $g\\circ f$\n",
    "we have: \n",
    "$$f\\circ g\\circ f (u)= f(u)=f(\\lambda u)=\\lambda f(u)\\\\\n",
    "\\implies \\lambda = 1 \\text{ or } f(u)=0 \\implies \\lambda = 1 \\text{ or } g\\circ f(u)=\\lambda u = 0  \\implies \\lambda \\in \\{0,1\\}$$\n",
    "\n",
    "We have $$\\begin{cases} \n",
    "\\ker f \\subset \\ker g\\circ f \\\\\n",
    "  \\ker g\\circ f \\subset \\ker f\\circ g \\circ f\n",
    "\\end{cases} \\implies \\begin{cases}\n",
    "\\ker f \\subset \\ker g\\circ f \\\\\n",
    "  \\ker g\\circ f \\subset \\ker f\n",
    "\\end{cases}\\implies \\ker g\\circ f= \\ker f$$\n",
    "\n",
    "Since every eigenvalue $\\lambda \\in\\{0,1\\}$ and $g\\circ f$ is self-adjoint, we have \n",
    "$$\\begin{cases}\n",
    "E = E_{g\\circ f,0}\\oplus E_{g\\circ f,1}\\\\\n",
    "E_{g\\circ f,0}=\\ker g\\circ f = \\ker f\\\\\n",
    "E_{g\\circ f,1}=E_{g\\circ f,0}^\\perp = \\left(\\ker f \\right)^\\perp\n",
    "\\end{cases}$$\n",
    "\n",
    "Let $\\mathscr{B}=\\left(u_1,\\dots,u_p\\right)$ an orthonormal basis of $\\ker f^\\perp$.\n",
    "\n",
    "Since $\\mathscr{B}$ is a basis of $\\ker f^\\perp = E_{g\\circ f,1}$ which is an eigenspace with $\\lambda = 1 \\neq 0$, we have then $f\\left(\\mathscr{B}\\right)=\\left(f(u_1),\\dots,f(u_p)\\right)$ is a basis of $F_{f\\circ g,1}$\n",
    " \n",
    "Furthermore, since $f\\circ g$ and $g\\circ f$ have the same non-zero eigenvalues, we have every eigenvalue $\\lambda$ of $f\\circ g$ is either $0$ or $1$ \n",
    "$$\\begin{cases}\n",
    "F = F_{f\\circ g,0}\\oplus F_{f\\circ g,1}\\\\\n",
    "F_{f\\circ g,1}= f\\left(\\ker f ^\\perp\\right) = \\im f\\\\\n",
    "F_{f\\circ g,0}=F_{f\\circ g,1}^\\perp = f\\left(\\ker f ^\\perp\\right)^\\perp = \\im f^\\perp = \\ker f\\circ g = \\ker g\n",
    "\\end{cases}$$\n",
    "\n",
    "Now: \n",
    "$$\\forall i \\in \\{1,\\dots,p\\},\\quad g\\left(f(u_i)\\right)=g\\circ f(u_i) = u_i\\\\\n",
    "\\forall x \\in  \\im f^\\perp, \\quad g(x)=0 \n",
    "$$\n",
    "\n",
    "After this construction, we can verify such $g$ if it exists, is unique\n",
    "\n",
    "### 5.2 Existence\n",
    "\n",
    "Let $r$ be the rank of $f$\n",
    "\n",
    "We have $\\dim \\ker f^\\perp= \\dim E - \\dim \\ker f$, and by the rank-nullity theorem, we have \n",
    "$r = \\dim \\im f = \\dim E - \\dim \\ker f$. \n",
    "\n",
    "So $f$ is an isomorphism from $\\ker f^\\perp$ to $\\im f$\n",
    "\n",
    "Let $\\mathscr{B}=\\left(u_1,\\dots,u_n\\right)$ an orthonormal basis of $E$ with:\n",
    "1. $\\mathscr{B}_1= \\left(u_1,\\dots,u_r\\right)$ an orthonormal basis of $\\ker f^\\perp$\n",
    "2. $\\mathscr{B}_2= \\left(u_{1+r},\\dots,u_n\\right)$ an orthonormal basis of $\\ker f$\n",
    "\n",
    "we have then $f\\left(\\mathscr{B_1}\\right)$ is a basis of $\\im f$\n",
    "\n",
    "Let $\\mathscr{D}=\\left(v_1,\\dots,v_m\\right)$ an orthonormal basis of $F$ with:\n",
    "1. $\\mathscr{D}_1= \\left(v_1,\\dots,v_r\\right)$ an orthonormal basis of $\\im f$\n",
    "2. $\\mathscr{D}_2= \\left(v_{1+r},\\dots,u_m\\right)$ an orthonormal basis of $\\im f ^\\perp$\n",
    "\n",
    "\n",
    "Let $g\\in \\mathscr{L}\\left(F,E\\right)/ \\quad \\begin{cases}\n",
    "g\\circ f \\left(\\mathscr{B}_1\\right)=\\mathscr{B}_1 \\\\\n",
    "\\ker g = \\im f^\\perp\n",
    "\\end{cases}$\n",
    "\n",
    "By construction, such $g$ is unique, and it is easy to prove that \n",
    "$$\n",
    "g_{\\mid \\im f} = f_{\\mid \\ker f^\\perp}^{-1} \\\\\n",
    "\\implies \n",
    "\\begin{cases}\n",
    "\\forall x \\in \\ker f^\\perp, \\quad g\\circ f(x)=g_{\\mid \\im f}\\circ f_{\\mid \\ker f^\\perp}(x)= x\\\\\n",
    "\\forall x=f(s) \\in \\im f,s\\in \\ker f^\\perp,\\quad f\\circ g (x) = f\\circ g \\circ f(s)=f(s)=x \n",
    "\\end{cases}\n",
    "$$\n",
    "So we have $$\n",
    "\\begin{cases}\n",
    "    \\mat(g\\circ f,\\mathscr{B})= \n",
    "    \\begin{pmatrix}\n",
    "        I_r & \\boldsymbol{0}\\\\\n",
    "        \\boldsymbol{0} & \\boldsymbol{0}\n",
    "    \\end{pmatrix}\n",
    "    \\\\\n",
    "    \\mat(f\\circ g,\\mathscr{D})= \n",
    "    \\begin{pmatrix}\n",
    "        I_r & \\boldsymbol{0}\\\\\n",
    "        \\boldsymbol{0} & \\boldsymbol{0}\n",
    "    \\end{pmatrix}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "now we verify that $g$ is a Moore-Penrose pseudoinverse of $f$\n",
    "- $ \\forall x=a+b,(a,b) \\in \\ker f\\times \\ker f^\\perp, \\quad f\\circ g \\circ f (x)= f\\circ g \\circ f (a) +  f\\circ g \\circ f (b)=   f(b) = f(b) + f(a) = f(x)$\n",
    "- $ \\forall \\omega=\\alpha+\\beta,(\\alpha,\\beta) \\in \\im f\\times \\im f^\\perp,\\\\\n",
    "\\quad g\\circ f \\circ g (\\omega) = g\\circ f \\circ g (\\alpha) +  g\\circ f \\circ g (\\beta)=  g\\circ f \\circ g (\\alpha) = g (\\alpha) =g (\\alpha)+g (\\beta)=g(\\omega) $\n",
    "- since the matrice of $g\\circ f$ in the orthonormal basis $\\mathscr{B}$ is hermitian, we have $g\\circ f$ is self-adjoint\n",
    "- since the matrice of $f\\circ g$ in the orthonormal basis $\\mathscr{D}$ is hermitian, we have $f\\circ g$ is self-adjoint\n",
    "\n",
    "- Conclusion:\n",
    "$g=f^+$ is the Moore-Penrose pseudoinverse of $f$\n",
    "\n",
    "## 6. Calculating the pseudoinverse from the SVD\n",
    "Let $M \\in \\mathbb{R}^{m\\times n}$\n",
    "Let $U\\in \\mathscr{U}(n),V\\in \\mathscr{U}(m)$ and $\\Sigma \\in \\mathbb{R}^{m\\times n}$ a diagonal matrix such that:\n",
    "$$ M = U\\Sigma V^*$$\n",
    "We have the following equality:\n",
    "$$ \\begin{cases}\n",
    "M^+= V\\Sigma^+U^*\\\\\n",
    "\\Sigma^+\\in \\mathbb{R}^{n\\times m} \\text{ is diagonal}\\\\\n",
    "\\Sigma^+_{i,i} = \\begin{cases}\n",
    "    \\frac{1}{\\Sigma_{i,i}} \\text{ if } \\Sigma_{i,i} \\neq 0 \\\\\n",
    "    0\n",
    "\\end{cases}\n",
    "\\end{cases}\n",
    "$$\n",
    "In fact $\\Sigma^+$ is pseudoinverse of $\\Sigma$\n",
    "\n",
    "## 7. Proprieties\n",
    "Let $f\\in\\mathscr{L}\\left(E,F\\right)$\n",
    "1. $(f^+)^+=f$\n",
    "2. $\\ker f^+ = \\im f^\\perp$\n",
    "3. $f^+\\circ f = \\Pi_{\\ker f^\\perp}$\n",
    "4. $f \\circ f^+ = \\Pi_{\\ker (f^+)^\\perp}=\\Pi_{\\im f}$\n",
    "5. $f^*\\circ f \\circ f^+ =f^* $\n",
    "6. $f^+\\circ f \\circ f^*= f^*$\n",
    "7. if $f$ is injective $\\iff \\ker f = \\{\\boldsymbol{0}\\}: \\quad f^+=\\left(f^*\\circ f\\right)^{-1}f^*$\n",
    "8. if $f^*$ is injective $\\iff \\ker f^* = \\im f ^\\perp = \\{\\boldsymbol{0}\\}\\iff \\im f = F \\iff f$ is surjective: $f^+=f^* \\circ \\left(f\\circ f^*\\right)^{-1}$\n",
    "9. $\\left(f^*\\right)^+=\\left(f^+\\right)^*$\n",
    "10. $\\left(f^T\\right)^+=\\left(f^+\\right)^T$ (ordinary transpose)\n",
    "11. $\\bar{f}^+=\\bar{f^+}$\n",
    "12. $\\left(f\\circ f^*\\right)^+= \\left(f^*\\right)^+f^+$\n",
    "13. $\\left(f^*\\circ f\\right)^+= f^+ \\left(f^*\\right)^+$\n",
    "\n",
    "## 8. Applications\n",
    "We will consider the linear system $Ax=b$\n",
    "\n",
    "### 8.1 Solving linear system\n",
    "$Ax=b \\implies A^+Ax=A^+b\\implies AA^+Ax=Ax=AA^+b\\implies b=AA^+b$\n",
    "\n",
    "Let $(u,v)\\in \\ker A\\times \\ker A ^\\perp/x = u + v$\n",
    "We have \n",
    "$$A^+Ax=\\Pi_{\\ker A^\\perp}x=v=A^+b\\implies x = A^+b + u = A^+b + \\Pi_{\\ker A}w,w\\in E \\\\\n",
    "= A^+b+(I_n-\\Pi_{\\ker A^\\perp})w=A^+b + (I_n-A^+A)w\n",
    "$$\n",
    "\n",
    "Let $w\\in E$\n",
    "$$A(A^+b + (I_n-A^+A)w) =AA^+b+(A-AA^+A)w=AA^+b$$\n",
    "1. So this equation has solutions if and only if $b = AA^+b \\iff b = \\Pi_{\\im A}b \\iff b\\in \\im A$\n",
    "2. This solution is unique if and only if $A^+A=I_n=\\Pi_{\\ker A^\\perp} \\iff \\ker A^\\perp = E \\iff \\ker A=\\{\\boldsymbol{0}\\} \\iff A$ is injective\n",
    "3. a solution exists $\\forall b\\in F \\iff \\im A = F \\iff A$ is surjective\n",
    "\n",
    "### 8.2 Minimum norm solution to a linear system\n",
    "supposing that $b\\in \\im A$\n",
    "Let $x$ be a solution to $Ax=b$\n",
    "we have then $\\exists w\\in E/\\quad x=A^+b+(I_n-A^+A)w$\n",
    "\n",
    "Or we have $A^+b \\in \\ker A^\\perp$ and $(I_n-A^+A)w \\in \\ker A$, so we have:\n",
    "$$ \\lVert x \\rVert_2^2= \\lVert A^+b \\rVert_2^2+\\lVert (I_n-A^+A)w \\rVert_2^2 $$\n",
    "We have $\\lVert x \\rVert_2^2\\ge \\lVert A^+b \\rVert_2^2$ with equality if and only if $\\lVert (I_n-A^+A)w \\rVert_2^2 = 0 \\iff w \\in \\ker A^\\perp$\n",
    "\n",
    "So $x=A^+b$ is the solution of $Ax=b$ with the smallest norm\n",
    "\n",
    "### 8.3 Least square solutions for $Ax = b$\n",
    "- This technique is used for Linear Regression $(\\mathbb{K}=\\mathbb{R}$):\n",
    "\n",
    "#### 8.3.1 Analytic Derivation\n",
    "Even though the equation can have no solution, we want to find $x$ that minimise the error $\\epsilon = \\lVert Ax-b \\rVert$\n",
    "\n",
    "Because $\\epsilon \\ge 0$, minimising $\\epsilon$ is the same as minimising $\\epsilon^2$, or $\\epsilon^2$ is a positive semi-definite quadratic form, so it has a minimum:\n",
    "$$ \\dfrac{\\partial \\epsilon^2}{\\partial x} = 2 (Ax-b)^TA=\\boldsymbol{0}\\iff A^T(Ax-b)=\\boldsymbol{0} \\iff A^TAx=A^Tb$$\n",
    "Now that equation should have solutions, because every positive semi-definite quardatic form has a minimum value.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\left(A^TA\\right)\\left(A^TA\\right)^+\\left(A^Tb\\right) & =\\left(A^TA\\right)\\left(A^+\\left(A^T\\right)^+A^T\\right)b\\\\\n",
    "& =\\left(A^TA\\right)\\left(A^+\\left(AA^+\\right)^T\\right)b \\\\\n",
    "& =\\left(A^TA\\right)\\left(A^+AA^+\\right)b\\\\\n",
    " &=A^TAA^+b=A^T(AA^+)^Tb=A^T(A^T)^+A^Tb=A^Tb\n",
    "\\end{align}\n",
    "$$\n",
    "So indeed, this equation has solutions and by noting that: \n",
    "$$ \\begin{align}\n",
    "\\left(A^TA\\right)^+\\left(A^TA\\right)& =A^+\\left(A^+\\right)^T A^TA\\\\ \n",
    "& = A^+\\left(AA^+\\right)^TA \\\\\n",
    "&=A^+AA^+A\\\\\n",
    "&=A^+A\n",
    "\\left(A^TA\\right)^+A^T & = A^+\\left(A^+\\right)^TA^T\\\\\n",
    "& =A^+\\left(AA^+\\right)^T\\\\\n",
    "& = A^+AA^+\\\\\n",
    "& = A^+\n",
    "\\end{align}\n",
    "$$\n",
    "We have:\n",
    "$ x = A^+b+(I_n-A^+A), \\quad w\\in E$\n",
    "\n",
    "#### 8.3.2 Geometric Derivation\n",
    "\n",
    "we know that the distance between the vector space $\\im A$ and the point $b$ is given by:\n",
    "$$ \\lVert b- \\Pi_{\\im A}b\\rVert =  \\lVert b- AA^+b \\rVert$$\n",
    "That minimal distance occurs at $$\\begin{align}\n",
    "x & =A^+\\Pi_{\\im A}b + (I_n-A^+A)w\\\\\n",
    "& =A^+AA^+b+(I_n-A^+A)w \\\\\n",
    "& =A^+b+(I_n-A^+A)w \\quad,w\\in E\n",
    "\\end{align}$$\n",
    "\n",
    "#### 8.3.3 Solution for Linear Regression\n",
    "For Linear regression, we usually pick the solution with the smallest $ \\mathscr{L}^2 $ norm, so we pick:\n",
    "$$ x = \\left(A^TA\\right)^+A^Tb = A^+b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=np.random.normal(0,1,[5,8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.54307003e-17,  1.00000000e+00,  1.00000000e+00, -6.21984137e-17,\n",
       "         1.81786966e-17,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00]),\n",
       " array([[-0.62097469, -0.63870172, -0.50130372,  0.57140508, -0.43059727,\n",
       "         -0.56080997,  0.48383989,  0.60314584],\n",
       "        [-0.11488568,  0.08971696,  0.07883548, -0.03358621, -0.26112962,\n",
       "          0.35491226, -0.00298979, -0.04740202],\n",
       "        [-0.11559336,  0.48744983,  0.60604589,  0.14858841, -0.02313218,\n",
       "          0.38650976, -0.7627385 , -0.38677664],\n",
       "        [-0.57003302,  0.3510206 ,  0.26632744,  0.58093214, -0.3615896 ,\n",
       "          0.23553017, -0.13637124, -0.21964313],\n",
       "        [ 0.3010795 ,  0.13587481,  0.28539573, -0.16061199,  0.12430355,\n",
       "          0.26322566, -0.05520717, -0.16754957],\n",
       "        [-0.302208  ,  0.28743257,  0.27558355,  0.42012666,  0.19358585,\n",
       "          0.43486656, -0.2210091 , -0.44079322],\n",
       "        [-0.06128502, -0.11933758, -0.17967516,  0.31896403, -0.31482021,\n",
       "         -0.09403791,  0.09486671,  0.12187148],\n",
       "        [ 0.27777302, -0.32843154, -0.33849289, -0.09363154,  0.68049729,\n",
       "         -0.29567788,  0.32346613,  0.44598732]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(np.linalg.pinv(M)@M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.random.normal(0,.1,[2,3])\n",
    "B=np.random.normal(0,.1,[3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99961231,  0.37137461],\n",
       "       [-0.02784311, -0.92848312]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Âµ,U=np.linalg.eig(A@B)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "s,V=np.linalg.eig(B@A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06090264,  0.96750812],\n",
       "       [ 0.8529017 , -0.05766297],\n",
       "       [-0.51850704, -0.24617682]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(B@U)/np.linalg.norm(B@U,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06090264,  0.96750812,  0.48994145],\n",
       "       [ 0.8529017 , -0.05766297,  0.85911506],\n",
       "       [-0.51850704, -0.24617682,  0.14791447]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
